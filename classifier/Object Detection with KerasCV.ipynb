{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b696e5a-7f19-4cf6-8c63-675ba044c20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-macos 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade keras-cv\n",
    "!pip install -q --upgrade keras  # Upgrade to Keras 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b33469d2-915e-4b67-ab23-851968eec4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jax in ./venv/lib/python3.11/site-packages (0.4.24)\n",
      "Requirement already satisfied: jaxlib in ./venv/lib/python3.11/site-packages (0.4.24)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in ./venv/lib/python3.11/site-packages (from jax) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.22 in ./venv/lib/python3.11/site-packages (from jax) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum in ./venv/lib/python3.11/site-packages (from jax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in ./venv/lib/python3.11/site-packages (from jax) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U jax jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11106797-b7f4-4eda-8085-28ce4fd5fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jaxlib\n",
      "  Downloading jaxlib-0.4.24-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: scipy>=1.9 in ./venv/lib/python3.11/site-packages (from jaxlib) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.22 in ./venv/lib/python3.11/site-packages (from jaxlib) (1.26.4)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in ./venv/lib/python3.11/site-packages (from jaxlib) (0.2.0)\n",
      "Downloading jaxlib-0.4.24-cp311-cp311-macosx_11_0_arm64.whl (68.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jaxlib\n",
      "Successfully installed jaxlib-0.4.24\n"
     ]
    }
   ],
   "source": [
    "!pip install jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b242a6-4789-4c15-9e7e-ff969a9a2e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow\n",
      "  Using cached pillow-10.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Using cached pillow-10.2.0-cp311-cp311-macosx_11_0_arm64.whl (3.3 MB)\n",
      "Installing collected packages: pillow\n",
      "Successfully installed pillow-10.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba5c3339-39fd-4a36-909d-be9b37b53057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ---------------\n",
      "absl-py                      1.4.0\n",
      "anyio                        4.3.0\n",
      "appnope                      0.1.4\n",
      "argon2-cffi                  23.1.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "arrow                        1.3.0\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "async-lru                    2.0.4\n",
      "attrs                        23.2.0\n",
      "Babel                        2.14.0\n",
      "beautifulsoup4               4.12.3\n",
      "bleach                       6.1.0\n",
      "cachetools                   5.3.2\n",
      "certifi                      2024.2.2\n",
      "cffi                         1.16.0\n",
      "charset-normalizer           3.3.2\n",
      "click                        8.1.7\n",
      "comm                         0.2.1\n",
      "debugpy                      1.8.1\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "dm-tree                      0.1.8\n",
      "etils                        1.7.0\n",
      "executing                    2.0.1\n",
      "fastjsonschema               2.19.1\n",
      "flatbuffers                  23.5.26\n",
      "fqdn                         1.5.1\n",
      "fsspec                       2024.2.0\n",
      "gast                         0.5.4\n",
      "google-auth                  2.28.0\n",
      "google-auth-oauthlib         1.2.0\n",
      "google-pasta                 0.2.0\n",
      "googleapis-common-protos     1.62.0\n",
      "grpcio                       1.60.1\n",
      "h11                          0.14.0\n",
      "h5py                         3.10.0\n",
      "httpcore                     1.0.3\n",
      "httpx                        0.26.0\n",
      "idna                         3.6\n",
      "importlib-resources          6.1.1\n",
      "ipykernel                    6.29.2\n",
      "ipython                      8.21.0\n",
      "ipywidgets                   8.1.2\n",
      "isoduration                  20.11.0\n",
      "jedi                         0.19.1\n",
      "Jinja2                       3.1.3\n",
      "json5                        0.9.17\n",
      "jsonpointer                  2.4\n",
      "jsonschema                   4.21.1\n",
      "jsonschema-specifications    2023.12.1\n",
      "jupyter                      1.0.0\n",
      "jupyter_client               8.6.0\n",
      "jupyter-console              6.6.3\n",
      "jupyter_core                 5.7.1\n",
      "jupyter-events               0.9.0\n",
      "jupyter-lsp                  2.2.2\n",
      "jupyter_server               2.12.5\n",
      "jupyter_server_terminals     0.5.2\n",
      "jupyterlab                   4.1.2\n",
      "jupyterlab_pygments          0.3.0\n",
      "jupyterlab_server            2.25.3\n",
      "jupyterlab_widgets           3.0.10\n",
      "kagglehub                    0.1.9\n",
      "keras                        3.0.5\n",
      "keras-core                   0.1.7\n",
      "keras-cv                     0.8.2\n",
      "libclang                     16.0.6\n",
      "Markdown                     3.5.2\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   2.1.5\n",
      "matplotlib-inline            0.1.6\n",
      "mdurl                        0.1.2\n",
      "mistune                      3.0.2\n",
      "ml-dtypes                    0.2.0\n",
      "namex                        0.0.7\n",
      "nbclient                     0.9.0\n",
      "nbconvert                    7.16.1\n",
      "nbformat                     5.9.2\n",
      "nest-asyncio                 1.6.0\n",
      "notebook                     7.1.0\n",
      "notebook_shim                0.2.4\n",
      "numpy                        1.26.4\n",
      "oauthlib                     3.2.2\n",
      "opt-einsum                   3.3.0\n",
      "overrides                    7.7.0\n",
      "packaging                    23.2\n",
      "pandocfilters                1.5.1\n",
      "parso                        0.8.3\n",
      "pexpect                      4.9.0\n",
      "pip                          24.0\n",
      "platformdirs                 4.2.0\n",
      "prometheus_client            0.20.0\n",
      "promise                      2.3\n",
      "prompt-toolkit               3.0.43\n",
      "protobuf                     3.20.3\n",
      "psutil                       5.9.8\n",
      "ptyprocess                   0.7.0\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.5.1\n",
      "pyasn1-modules               0.3.0\n",
      "pycparser                    2.21\n",
      "Pygments                     2.17.2\n",
      "python-dateutil              2.8.2\n",
      "python-json-logger           2.0.7\n",
      "PyYAML                       6.0.1\n",
      "pyzmq                        25.1.2\n",
      "qtconsole                    5.5.1\n",
      "QtPy                         2.4.1\n",
      "referencing                  0.33.0\n",
      "regex                        2023.12.25\n",
      "requests                     2.31.0\n",
      "requests-oauthlib            1.3.1\n",
      "rfc3339-validator            0.1.4\n",
      "rfc3986-validator            0.1.1\n",
      "rich                         13.7.0\n",
      "rpds-py                      0.18.0\n",
      "rsa                          4.9\n",
      "Send2Trash                   1.8.2\n",
      "setuptools                   69.0.2\n",
      "six                          1.16.0\n",
      "sniffio                      1.3.0\n",
      "soupsieve                    2.5\n",
      "stack-data                   0.6.3\n",
      "tensorboard                  2.15.2\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorflow                   2.15.0\n",
      "tensorflow-datasets          4.9.4\n",
      "tensorflow-estimator         2.15.0\n",
      "tensorflow-io-gcs-filesystem 0.36.0\n",
      "tensorflow-macos             2.15.0\n",
      "tensorflow-metadata          1.14.0\n",
      "tensorflow-metal             1.1.0\n",
      "termcolor                    2.4.0\n",
      "terminado                    0.18.0\n",
      "tinycss2                     1.2.1\n",
      "toml                         0.10.2\n",
      "tornado                      6.4\n",
      "tqdm                         4.66.2\n",
      "traitlets                    5.14.1\n",
      "types-python-dateutil        2.8.19.20240106\n",
      "typing_extensions            4.9.0\n",
      "uri-template                 1.3.0\n",
      "urllib3                      2.2.1\n",
      "wcwidth                      0.2.13\n",
      "webcolors                    1.13\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.7.0\n",
      "Werkzeug                     3.0.1\n",
      "wheel                        0.42.0\n",
      "widgetsnbextension           4.0.10\n",
      "wrapt                        1.14.1\n",
      "zipp                         3.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541bf3a4-4d0c-4c42-99fb-cf078428df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n",
    "\n",
    "from tensorflow import data as tf_data\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "import keras_cv\n",
    "import numpy as np\n",
    "from keras_cv import bounding_box\n",
    "import os\n",
    "from keras_cv import visualization\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665a8fb5-b589-4b8d-8357-adbd31b29734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/yolov8/keras/yolo_v8_m_pascalvoc/2/download/config.json...\n",
      "100%|██████████| 2.27k/2.27k [00:00<00:00, 1.87MB/s]\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/yolov8/keras/yolo_v8_m_pascalvoc/2/download/model.weights.h5...\n",
      "100%|██████████| 99.5M/99.5M [00:05<00:00, 17.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "    \"yolo_v8_m_pascalvoc\", bounding_box_format=\"xywh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ff5dd7-62c0-4bac-a124-14aaabd9e82c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m filepath \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mget_file(origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://i.imgur.com/gCNcJJI.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image)\n\u001b[1;32m      5\u001b[0m visualization\u001b[38;5;241m.\u001b[39mplot_image_gallery(\n\u001b[1;32m      6\u001b[0m     np\u001b[38;5;241m.\u001b[39marray([image]),\n\u001b[1;32m      7\u001b[0m     value_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m~/code/osu/cs461/classifier/venv/lib/python3.11/site-packages/keras/src/utils/image_utils.py:227\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03mUsage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    A PIL Image instance.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import PIL.Image. The use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m     )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, io\u001b[38;5;241m.\u001b[39mBytesIO):\n\u001b[1;32m    231\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(path)\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "filepath = keras.utils.get_file(origin=\"https://i.imgur.com/gCNcJJI.jpg\")\n",
    "image = keras.utils.load_img(filepath)\n",
    "image = np.array(image)\n",
    "\n",
    "visualization.plot_image_gallery(\n",
    "    np.array([image]),\n",
    "    value_range=(0, 255),\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    scale=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffaeda0-52e4-4111-bd33-c6420bfe7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_resizing = keras_cv.layers.Resizing(\n",
    "    640, 640, pad_to_aspect_ratio=True, bounding_box_format=\"xywh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75058ce8-5a63-4e19-a2ae-dc3197acad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = inference_resizing([image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f787c329-59de-4e85-9f14-2c1c19df1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = [\n",
    "    \"Aeroplane\",\n",
    "    \"Bicycle\",\n",
    "    \"Bird\",\n",
    "    \"Boat\",\n",
    "    \"Bottle\",\n",
    "    \"Bus\",\n",
    "    \"Car\",\n",
    "    \"Cat\",\n",
    "    \"Chair\",\n",
    "    \"Cow\",\n",
    "    \"Dining Table\",\n",
    "    \"Dog\",\n",
    "    \"Horse\",\n",
    "    \"Motorbike\",\n",
    "    \"Person\",\n",
    "    \"Potted Plant\",\n",
    "    \"Sheep\",\n",
    "    \"Sofa\",\n",
    "    \"Train\",\n",
    "    \"Tvmonitor\",\n",
    "    \"Total\",\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c40c7a-2d0a-4932-b6fc-15f24d8f58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pretrained_model.predict(image_batch)\n",
    "# y_pred is a bounding box Tensor:\n",
    "# {\"classes\": ..., boxes\": ...}\n",
    "visualization.plot_bounding_box_gallery(\n",
    "    image_batch,\n",
    "    value_range=(0, 255),\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    y_pred=y_pred,\n",
    "    scale=5,\n",
    "    font_scale=0.7,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    class_mapping=class_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb12ad-47ab-4116-b009-38ac9242c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following NonMaxSuppression layer is equivalent to disabling the operation\n",
    "prediction_decoder = keras_cv.layers.NonMaxSuppression(\n",
    "    bounding_box_format=\"xywh\",\n",
    "    from_logits=True,\n",
    "    iou_threshold=1.0,\n",
    "    confidence_threshold=0.0,\n",
    ")\n",
    "pretrained_model = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "    \"yolo_v8_m_pascalvoc\",\n",
    "    bounding_box_format=\"xywh\",\n",
    "    prediction_decoder=prediction_decoder,\n",
    ")\n",
    "\n",
    "y_pred = pretrained_model.predict(image_batch)\n",
    "visualization.plot_bounding_box_gallery(\n",
    "    image_batch,\n",
    "    value_range=(0, 255),\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    y_pred=y_pred,\n",
    "    scale=5,\n",
    "    font_scale=0.7,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    class_mapping=class_mapping,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce84a74-3026-4be1-a16f-9276d8bdf0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_decoder = keras_cv.layers.NonMaxSuppression(\n",
    "    bounding_box_format=\"xywh\",\n",
    "    from_logits=True,\n",
    "    # Decrease the required threshold to make predictions get pruned out\n",
    "    iou_threshold=0.2,\n",
    "    # Tune confidence threshold for predictions to pass NMS\n",
    "    confidence_threshold=0.7,\n",
    ")\n",
    "pretrained_model = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "    \"yolo_v8_m_pascalvoc\",\n",
    "    bounding_box_format=\"xywh\",\n",
    "    prediction_decoder=prediction_decoder,\n",
    ")\n",
    "\n",
    "y_pred = pretrained_model.predict(image_batch)\n",
    "visualization.plot_bounding_box_gallery(\n",
    "    image_batch,\n",
    "    value_range=(0, 255),\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    y_pred=y_pred,\n",
    "    scale=5,\n",
    "    font_scale=0.7,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    class_mapping=class_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56af5128-430d-4b94-b698-33430c6734ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553193c-81c7-4382-b125-4f11a237ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n",
    "    inputs = next(iter(inputs.take(1)))\n",
    "    images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=value_range,\n",
    "        rows=rows,\n",
    "        cols=cols,\n",
    "        y_true=bounding_boxes,\n",
    "        scale=5,\n",
    "        font_scale=0.7,\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        class_mapping=class_mapping,\n",
    "    )\n",
    "\n",
    "\n",
    "def unpackage_raw_tfds_inputs(inputs, bounding_box_format):\n",
    "    image = inputs[\"image\"]\n",
    "    boxes = keras_cv.bounding_box.convert_format(\n",
    "        inputs[\"objects\"][\"bbox\"],\n",
    "        images=image,\n",
    "        source=\"rel_yxyx\",\n",
    "        target=bounding_box_format,\n",
    "    )\n",
    "    bounding_boxes = {\n",
    "        \"classes\": inputs[\"objects\"][\"label\"],\n",
    "        \"boxes\": boxes,\n",
    "    }\n",
    "    return {\"images\": image, \"bounding_boxes\": bounding_boxes}\n",
    "\n",
    "\n",
    "def load_pascal_voc(split, dataset, bounding_box_format):\n",
    "    ds = tfds.load(dataset, split=split, with_info=False, shuffle_files=True)\n",
    "    ds = ds.map(\n",
    "        lambda x: unpackage_raw_tfds_inputs(x, bounding_box_format=bounding_box_format),\n",
    "        num_parallel_calls=tf_data.AUTOTUNE,\n",
    "    )\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = load_pascal_voc(\n",
    "    split=\"train\", dataset=\"voc/2007\", bounding_box_format=\"xywh\"\n",
    ")\n",
    "eval_ds = load_pascal_voc(split=\"test\", dataset=\"voc/2007\", bounding_box_format=\"xywh\")\n",
    "\n",
    "train_ds = train_ds.shuffle(BATCH_SIZE * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9103327e-944b-4a80-99a0-d3fb7dabf162",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "eval_ds = eval_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e2d5b-8d9c-48bd-aa00-ec6ebcf13b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(\n",
    "    train_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1430e064-4ada-4f7c-9e35-8d844a61831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(\n",
    "    eval_ds,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    value_range=(0, 255),\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    # If you are not running your experiment on a local machine, you can also\n",
    "    # make `visualize_dataset()` dump the plot to a file using `path`:\n",
    "    # path=\"eval.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f8866-49ea-411c-b0d9-9f8dcdcfc7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenters = [\n",
    "    keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xywh\"),\n",
    "    keras_cv.layers.JitteredResize(\n",
    "        target_size=(640, 640), scale_factor=(0.75, 1.3), bounding_box_format=\"xywh\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "def create_augmenter_fn(augmenters):\n",
    "    def augmenter_fn(inputs):\n",
    "        for augmenter in augmenters:\n",
    "            inputs = augmenter(inputs)\n",
    "        return inputs\n",
    "\n",
    "    return augmenter_fn\n",
    "\n",
    "\n",
    "augmenter_fn = create_augmenter_fn(augmenters)\n",
    "\n",
    "train_ds = train_ds.map(augmenter_fn, num_parallel_calls=tf_data.AUTOTUNE)\n",
    "visualize_dataset(\n",
    "    train_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0614b1f9-bc01-4441-897f-e4f55c70ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_resizing = keras_cv.layers.Resizing(\n",
    "    640, 640, bounding_box_format=\"xywh\", pad_to_aspect_ratio=True\n",
    ")\n",
    "eval_ds = eval_ds.map(inference_resizing, num_parallel_calls=tf_data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a2158-eddd-426e-b2b7-e1eb532debb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(\n",
    "    eval_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c353a08c-9deb-48d6-a1c6-78adc8664fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dict_to_tuple(inputs):\n",
    "    return inputs[\"images\"], bounding_box.to_dense(\n",
    "        inputs[\"bounding_boxes\"], max_boxes=32\n",
    "    )\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf_data.AUTOTUNE)\n",
    "eval_ds = eval_ds.map(dict_to_tuple, num_parallel_calls=tf_data.AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.prefetch(tf_data.AUTOTUNE)\n",
    "eval_ds = eval_ds.prefetch(tf_data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b12c8-3dcd-46d2-8ef3-58d1320451c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = 0.005\n",
    "# including a global_clipnorm is extremely important in object detection tasks\n",
    "optimizer = keras.optimizers.SGD(\n",
    "    learning_rate=base_lr, momentum=0.9, global_clipnorm=10.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaaa64e-09f1-4da2-be14-7fee884115d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.compile(\n",
    "    classification_loss=\"binary_crossentropy\",\n",
    "    box_loss=\"ciou\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84841b7c-d417-4417-a279-58080a2df084",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_metrics_callback = keras_cv.callbacks.PyCOCOCallback(\n",
    "    eval_ds.take(20), bounding_box_format=\"xywh\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcfe9bc-5f7f-4cac-b04e-0fd35ba09283",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "    \"resnet50_imagenet\",\n",
    "    # For more info on supported bounding box formats, visit\n",
    "    # https://keras.io/api/keras_cv/bounding_box/\n",
    "    bounding_box_format=\"xywh\",\n",
    "    num_classes=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c9a8b-e0ad-40a5-98ef-87410ba1d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    classification_loss=\"binary_crossentropy\",\n",
    "    box_loss=\"ciou\",\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112ba49-9f9b-495b-ab8e-a732a5f7b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_ds.take(20),\n",
    "    # Run for 10-35~ epochs to achieve good scores.\n",
    "    epochs=1,\n",
    "    callbacks=[coco_metrics_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991c347-5df5-49df-ae8b-8c9236a4d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "    \"yolo_v8_m_pascalvoc\", bounding_box_format=\"xywh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130cfa69-5795-4f3c-a191-2d54e850a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_ds = eval_ds.unbatch()\n",
    "visualization_ds = visualization_ds.ragged_batch(16)\n",
    "visualization_ds = visualization_ds.shuffle(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539d3e8-7345-48a4-89d1-7f49d1a64400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_detections(model, dataset, bounding_box_format):\n",
    "    images, y_true = next(iter(dataset.take(1)))\n",
    "    y_pred = model.predict(images)\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=(0, 255),\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        scale=4,\n",
    "        rows=2,\n",
    "        cols=2,\n",
    "        show=True,\n",
    "        font_scale=0.7,\n",
    "        class_mapping=class_mapping,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fbdaf1-fc90-45d1-bd6b-30dff95e00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prediction_decoder = keras_cv.layers.NonMaxSuppression(\n",
    "    bounding_box_format=\"xywh\",\n",
    "    from_logits=True,\n",
    "    iou_threshold=0.5,\n",
    "    confidence_threshold=0.75,\n",
    ")\n",
    "\n",
    "visualize_detections(model, dataset=visualization_ds, bounding_box_format=\"xywh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70790a40-80f3-46c1-8167-0f3bb3fd5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VisualizeDetections(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        visualize_detections(\n",
    "            self.model, bounding_box_format=\"xywh\", dataset=visualization_ds\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c9e85a-2064-4c82-b9ed-23ba1b6b9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_diffusion = keras_cv.models.StableDiffusionV2(512, 512)\n",
    "images = stable_diffusion.text_to_image(\n",
    "    prompt=\"A zoomed out photograph of a cool looking cat.  The cat stands in a beautiful forest\",\n",
    "    negative_prompt=\"unrealistic, bad looking, malformed\",\n",
    "    batch_size=4,\n",
    "    seed=1231,\n",
    ")\n",
    "encoded_predictions = model(images)\n",
    "y_pred = model.decode_predictions(encoded_predictions, images)\n",
    "visualization.plot_bounding_box_gallery(\n",
    "    images,\n",
    "    value_range=(0, 255),\n",
    "    y_pred=y_pred,\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    scale=5,\n",
    "    font_scale=0.7,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    class_mapping=class_mapping,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifier",
   "language": "python",
   "name": "classifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
